# -*- coding: utf-8 -*-
"""Copy of pandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/zacharski/ml-class/blob/master/labs/pandas.ipynb

# Intro to Pandas

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/pandas-logo-2.png)

<font size='0.85em'>(logo by [Marc Garcia](https://github.com/pandas-dev/pandas/blob/master/web/pandas/static/img/pandas.svg))</font> 


> A suggestion: This worksheet is organized in a way that, hopefully, best presents the topics and not in a way that is the most useful for reference. As you progress through this worksheet, your future you will find it useful if you create your own notes so that you can quickly find the relevant information. These notes might take the form of a separate Google Colab notebook or handwritten notes. In addition, just the activity of taking notes will help you retain the information.

The Pandas Library is built on top of Numpy and is designed to make working with data fast and easy. Like Numpy, the library includes data structures and functions to manipulate that data.

As we learned in the Numpy Notebook, we need to load in the library before we can use it.
"""

from pandas import Series, DataFrame
import numpy as np
import pandas as pd

"""Let's dissect the code above.

The `Series` and `DataFrame` datatypes are commonly used so we import them directly with

```
from pandas import Series, DataFrame
```

For all other datatypes and functions in the library, the `pd` prefix is commonly used so we import that with

```
import pandas as pd
```

## Series
A series is a 1d array-like object

Let's consider the heights (in cm) of the members of the Japan's Women's Basketball Team at the 2020 Olympics (they won the silver medal).      

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/basketball2020.png)
We can create a series in a number of ways.

For example, we can create it directly from a Python list
"""

japan = [183, 185, 167, 162, 165, 174, 173, 181, 167, 183, 185, 182] # a Python list
athletesHeight = Series(japan) # converted to a Pandas Series

"""We could also have done"""

athletesHeight = Series([183, 185, 167, 162, 165, 174, 173, 181, 167, 183, 185, 182])

"""In either case we can see the value of the Series `athletesHeight`"""

athletesHeight

"""You are probably familiar with arrays in programming languages and this works in a similar way. The left number is the index and the right the value. And we can find the value at a particular index by the usual:"""

athletesHeight[3]

"""#### specifying indices
Instead of the index 0, 1, 2, 3 ... you can specify your own index values. For example, we can label them 'Moeko Nagaoka', 'Maki Takada', 'Naho Miyoshi' ... etc. 
"""

athletes2 = Series(japan, index = ['Moeko Nagaoka', 'Maki Takada', 'Naho Miyoshi', 
                                   'Rui Machida', 'Nako Motohashi', 'Nanaka Todo', 
                                   'Saki Hayashi','Evelyn Mawuli', 'Saori Miyazaki', 'Yuki Miyazawa', 'Himawari Akaho', 
                                   'Monica Okoye'])
athletes2

"""The names we see are not another column of the data. We can see the shape of athletes2 by:"""

athletes2.shape

"""This shows that athletes2 is a one dimensional matrix and that dimension has a length of 12. So the names we see are not values in a column but rather the indices.


Let's use the index to get the Height of Himawari Akaho:
"""

athletes2['Himawari Akaho']

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)
## DataFrame
DataFrames are **the most important data structure of Pandas** and are simply
a table or spreadsheet like structure.  A DataFrame represents a table like:
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/ioniq5s.png)

Make | Drive | Range | Battery_kwH | PeakPower_kW | MPGe | 0-60
:---- | :--- | ---: | ---: | ---: | ---: | ---:
Ioniq 5 | AWD | 256 | 77.4 | 239 | 98 | 5.0
Tesla Model 3 | AWD | 315 | 80 | 298 | 113 | 3.1
Rivian R1T | AWD | 316 | 135 | 562 | 70 | 3.0 
VW ID.4 | RWD | 260 | 82 | 260 | 107 |  7.7
F150 Lightning | AWD | 230 | 110 | 318 | 68 | 4.0

### Creating a DataFrame by Hand

A common way to create a DataFrame is to use a Python dictionary as follows:"""

cars = {'Make': ['Ioniq 5', 'Tesla Model 3', 'Rivian R1T', 'VW ID.4', 'F150 Lightning'],
         'Drive': ['AWD', 'AWD', 'AWD', 'RWD', 'AWD'],
         'Range': [256, 315, 316, 260, 230],
         'Battery_kwH': [77.4, 80, 135, 82, 110],
         'PeakPower_kW': [239, 298, 562, 260, 318],
         'MPGe': [98, 113, 70, 107, 68],
         '0-60': [5.0, 3.1, 3.0, 7.7, 4.0]}

"""and now we can create a DataFrame from the `cars` Python dictionary:"""

df = DataFrame(cars)
df

"""Prior to my life with Pandas, I would represent a table like the above one as:"""

prePandas = [{'Make': 'Ioniq 5', 'Drive': 'AWD', 'Range': 256, 'Battery_kwH': 77.4, 'PeakPower_kW': 98, 'MPGe': 98, '0-60': 5.0},
             {'Make': 'Tesla Model 3', 'Drive': 'AWD', 'Range': 315, 'Battery_kwH': 80.0, 'PeakPower_kW': 113,'MPGe': 113, '0-60': 3.1},
             {'Make': 'Rivian R1T', 'Drive': 'AWD', 'Range': 316, 'Battery_kwH': 135.0, 'PeakPower_kW': 562,'MPGe': 70, '0-60': 3.0},
             {'Make': 'VW ID.4', 'Drive': 'RWD', 'Range': 260, 'Battery_kwH': 82.0, 'PeakPower_kW': 260,'MPGe': 107, '0-60': 7.7},
             {'Make': 'F150 Lightning', 'Drive': 'AWD', 'Range': 230, 'Battery_kwH': 110.0, 'PeakPower_kW': 318,'MPGe': 68, '0-60': 4.0}]


prePandas[0]['Make']

"""In the prePandas scheme the data is organized first by rows. That seemed logical to me since each row represents an object and is how we organize data in an SQL database. In the Pandas representation the data is organized by columns.

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Reading data from a csv file:

A CSV file (comma separated values) is a common data format for data science files. As| the name suggests, the data values in a row are separated by commas. For example, the data file to represent the table:


Make | Drive | Range | Battery_kwH | PeakPower_kW | MPGe | 0-60
:---- | :--- | ---: | ---: | ---: | ---: | ---:
Ioniq 5 | AWD | 256 | 77.4 | 239 | 98 | 5.0
Tesla Model 3 | AWD | 315 | 80 | 298 | 113 | 3.1
Rivian R1T | AWD | 316 | 135 | 562 | 70 | 3.0 
VW ID.4 | RWD | 260 | 82 | 260 | 107 |  7.7
F150 Lightning | AWD | 230 | 110 | 318 | 68 | 4.0


would be

```
Make,Drive,Range,Battery_kwH,PeakPower_kW,MPGe,0-60
Ioniq 5,AWD,256,77.4,239,98,5.0
Tesla Model 3,AWD,315,80,298,113,3.1
Rivian R1T,AWD,316,135,562,70,3.0 
VW ID.4,RWD,260,82,260,107,7.7
F150 Lightning,AWD,230,110,318,68,4.0

```


As the name suggests, we use the `pd.read_csv` function to read a csv file.  `pd.read_csv` can read a csv file from either your local machine or the web. Let's start with the web.

### Reading a CSV file from the web.
To read a file from the web, we simply provide a URL:
"""

evs = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ElectricCarData_Clean.csv')
evs

"""Sometimes the csv file has a header row as was the case in the example above. That file starts with the line
```
Brand,Model,AccelSec,TopSpeed_KmH,Range_Km,Efficiency_WhKm,FastCharge_KmH,RapidCharge,PowerTrain,PlugType,BodyStyle,Segment,Seats,PriceEuro
```
as we can see by using `curl`


"""

!curl -s https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ElectricCarData_Clean.csv |  head

"""**An aside**

We can preface any Unix command with a bang (!) to have it execute in our Notebook.  This is amazingly handy:


"""

!ls

!pwd

"""### Files with No Header Row
Sometimes the csv file does not have a header row. So for example, data might start on the very first line of the file

```
Tesla ,Model 3 Long Range Dual Motor,4.6,233,450,161,940,Yes,AWD,Type 2 CCS,Sedan,D,5,55480
Volkswagen ,ID.3 Pure,10,160,270,167,250,Yes,RWD,Type 2 CCS,Hatchback,C,5,30000
Polestar ,2,4.7,210,400,181,620,Yes,AWD,Type 2 CCS,Liftback,D,5,56440
```

In that case you specify the names of the columns using the `names` parameter:
"""

columnNames = ['Brand','Model','AccelSec','TopSpeed_KmH','Range_Km','Efficiency_WhKm',
               'FastCharge_KmH','RapidCharge','PowerTrain','PlugType','BodyStyle',
               'Segment','Seats','PriceEuro']

evs2 = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ElectricCarData_Clean_NoHeader.csv', names=columnNames)
evs2

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

### Reading a CSV file the local machine
First, let's get that file onto our local machine:"""

curl https://raw.githubusercontent.com/zacharski/datamining-guide/master/data/ElectricCarData_Clean.csv > evs.csv

"""Hmm. That didn't work. Can you fix the error and rerun that cell?

---
Now we can specify the local file using `pd=read_csv`
"""

ev3 = pd.read_csv('evs.csv')
ev3

"""Suppose we want that file in a data directory. Let's go ahead and create the directory and move the file there."""

!mkdir data
!mv evs.csv data

"""Now when we load the file we need to give more of a path:"""

evs4 = pd.read_csv('data/evs.csv')
evs4

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Missing Data


In real machine learning tasks, we often encounter missing values.

### Missing Data in Files
For example, suppose we didn't know The Polestar 2's acceleration, the BMW iX3's top speed and the Honda's model name. In that case our CSV file would start


```
Brand,Model,AccelSec,TopSpeed_KmH,Range_Km
Tesla ,Model 3 Long Range Dual Motor,4.6,233,450
Volkswagen ,ID.3 Pure,10.0,160,270
Polestar ,2,,210,400
BMW ,iX3 ,6.8,,360
Honda ,,9.5,145,
```

with the double comma on the Polestar, BMW and Honda lines representing the missing data. When we read that file.

"""

evs5 = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ev_cars_small.csv')
evs5

"""We see that missing values are now the floating point values NaN meaning Not a Number. This NaN value is used even in columns that do not contain floating point values. For example, in row 4 above, Honda has NaN in the model name column. Wes McKinney, the developer of Pandas calls NaN a *sentinel* value that is easily detected and indicates a missing value.

### Special Characters Representing NaN in the Data File

Sometimes, special characters are used in a data file to represent missing values. For example, sometimes a dash is used ...

Brand|Model|AccelSec|TopSpeed_KmH|Range_Km
:--- | :--- | ---: | ---: | ---: |
Tesla |Model 3 Long Range Dual Motor|4.6|233|450
Volkswagen |ID.3 Pure|10.0|160|270
Polestar |2|-|210|400
BMW |iX3 |6.8|-|360
Honda |-|9.5|145|

The associated data file would look like

```
Brand,Model,AccelSec,TopSpeed_KmH,Range_Km
Tesla ,Model 3 Long Range Dual Motor,4.6,233,450
Volkswagen ,ID.3 Pure,10.0,160,270
Polestar ,2,-,210,400
BMW ,iX3 ,6.8,-,360
Honda ,-,9.5,145,
```

If we do not convert these to `NaN`, these dashes will create havoc with future calculations:

``` 
TypeError: can't multiply sequence by non-int of type 'float'
```

When we read in the csv file we need to convert the dashes to `NaN` by using the `na_values` parameter in `read_csv`. As you can see in the following example, our data file has the dashes 
"""

!curl https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ev_cars_small-dash.csv

"""and we can convert those to `NaN` when we read the file"""

evdash = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ev_cars_small-dash.csv',
                     na_values='-')
evdash[:6]

"""### Specifying Missing Values by hand
Suppose we didn't know the range of the Hyundai Ioniq 5 and the MPGe of the Tesla.

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/ioniq5s.png)

Make | Drive | Range | Battery_kwH | PeakPower_kW | MPGe | 0-60
:---- | :--- | ---: | ---: | ---: | ---: | ---:
Ioniq 5 | AWD | - | 77.4 | 239 | 98 | 5.0
Tesla Model 3 | AWD | 315 | 80 | 298 | - | 3.1
Rivian R1T | AWD | 316 | 135 | 562 | 70 | 3.0 
VW ID.4 | RWD | 260 | 82 | 260 | 107 |  7.7
F150 Lightning | AWD | 230 | 110 | 318 | 68 | 4.0

In that case we can create a dataframe like:
"""

cars3 = {'Make': ['Ioniq 5', 'Tesla Model 3', 'Rivian R1T', 'VW ID.4', 'F150 Lightning'],
         'Drive': ['AWD', 'AWD', 'AWD', 'RWD', 'AWD'],
         'Range': [np.nan, 315, 316, 260, 230],
         'Battery_kwH': [77.4, 80, 135, 82, 110],
         'PeakPower_kW': [239, 298, 562, 260, 318],
         'MPGe': [98, np.nan, 70, 107, 68],
         '0-60': [5.0, 3.1, 3.0, 7.7, 4.0]}
        
carz = DataFrame(cars3)
carz

"""where `np.nan` is Numpy's NaN.  We can also use Python's `None`:

"""

cars3 = {'Make': ['Ioniq 5', 'Tesla Model 3', 'Rivian R1T', 'VW ID.4', 'F150 Lightning'],
         'Drive': ['AWD', 'AWD', 'AWD', 'RWD', 'AWD'],
         'Range': [None, 315, 316, 260, 230],
         'Battery_kwH': [77.4, 80, 135, 82, 110],
         'PeakPower_kW': [239, 298, 562, 260, 318],
         'MPGe': [98, None, 70, 107, 68],
         '0-60': [5.0, 3.1, 3.0, 7.7, 4.0]}
        
carz = DataFrame(cars3)
carz

"""In addition to reading CSV files, there are many other ways of reading in data including from SQL databases, mongoDB, and webpages. See the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/) for details.

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Indices
In all the examples above, when we created a DataFrame, an auto-generated, auto-incrementing index was generated. So our initial data might look like:


Make | Drive | Range | Battery_kwH | PeakPower_kW | MPGe | 0-60
:---- | :--- | ---: | ---: | ---: | ---: | ---:
Ioniq 5 | AWD | - | 77.4 | 239 | 98 | 5.0
Tesla Model 3 | AWD | 315 | 80 | 298 | - | 3.1
Rivian R1T | AWD | 316 | 135 | 562 | 70 | 3.0 
VW ID.4 | RWD | 260 | 82 | 260 | 107 |  7.7
F150 Lightning | AWD | 230 | 110 | 318 | 68 | 4.0

But the DataFrame looks like ...
"""

carz

"""with the 0, 1, 2 ... indices added (the column on the left). This makes it handy when we want to access a particular row."""

carz.loc[4]

"""As you can see in the above code, we access a particular row (or rows) with the `loc` method.

Sometimes the rows in our data already have a unique identifier. For example in a data file for U.S. states each state might have the unique 2 character state code


![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/grayStates.png)

State|Name|Pop2022|Pop2021|Pop2010|TotalArea|LandArea
:--- | :--- | ---: | ---: | ---: | ---: | ---: | 
AK| Alaska| 720763|724357|713910|665384|570640.95
AL| Alabama|4949697|4934193|4785437|52420|50645.33
AR| Arkansas|3042017|3033946|2921964|53179|52035.48
AZ| Arizona|7640796|7520103|6407172|113990|113594.08

In that case we can use the unique identifier, in this case the 2 letter state code, as our index. 
"""

states = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/usStates.csv',
                     index_col='State')
states

"""We can access a particular row, say the info for New Mexico by """

states.loc['NM']

"""You can access a range of rows by the standard Python method:"""

states[:5]

"""or

"""

states[11:16]

"""or using these index values:"""

states['IA': 'KS']

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Retrieving particular columns
We can get a column of a DataFrame by using the column name:"""

states[['Pop2022']]

"""and we can get multiple columns by passing a list of column names"""

states[['Pop2022', 'Pop2010']]

"""### Returning rows with loc

As we have seen we can retrieve rows using the loc function. 

We can also get rows that match a specific criterion. For example, all states whose 2022 population exceeded 10 million. 
"""

populousStates = states.loc[states['Pop2022'] > 10000000] 
populousStates

"""Or let's say we are interested in the states that lost population between 2021 and 2022."""

states.loc[states['Pop2022'] < states['Pop2021']]

"""States that are over 10 million population and have lost population in 2022:"""

states.loc[(states['Pop2022'] < states['Pop2021']) & (states['Pop2022'] > 10000000)]

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Creating new columns

#### State Density

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/stateDensity.png)

Let's say we want to add a new column, Density, that gives the number of people per square mile of land area. So the Formula is



$$Density=\frac{Pop2022}{LandArea}$$

We can do that with
"""

states['Density'] = states['Pop2022'] / states['LandArea']
states[:5][['Name', 'Density']]
states

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Sorting

Density is nice but it would be nice if we ordered the DataFrame by Density..."""

states.sort_values(by=['Density'])

"""That is better, but perhaps we would like to order by densest states first and only show the top five ...
 
"""

states.sort_values(by=['Density'], ascending=False)[:5]

"""Finally, let's add a column, growth, that shows the percent change in population from 2021 to 2022.  That formula would be

$$Growth=(\frac{Pop2022}{Pop2021} - 1) \times 100  $$
"""

states['Growth'] = (states['Pop2022'] / states['Pop2021'] - 1) * 100
states[:10]

"""And let's find the 5 fastest growing states:"""

states.sort_values(by=['Growth'], ascending=False)[:5]

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## Descriptive Statistics on DataFrames
One handy function is `describe`"""

states.describe()

"""Alternatively, we could retrieve a specific statistic:

"""

states['Pop2022'].mean()

"""or find out how many states lost population in 2022 using `count`:"""

states.loc[states['Pop2022'] < states['Pop2021']][['Pop2022']].count()

"""Or get the total population of the United States (minus the District of Columbia)"""

states['Pop2022'].sum()

"""or to make that more readable"""

totalPop = "{:,}".format(states['Pop2022'].sum())
print('Total Population: ' + totalPop)

"""What percentage of the U. S. population is accounted for by the top 5 most populous states?"""

statesByPopulation = states.sort_values(by=['Pop2022'], ascending=False)[:10][['Pop2022']]
percent = (statesByPopulation.sum() / states['Pop2022'].sum()) * 100
print("The top 10 most populous states account for {:4.2f} percent of the U.S. Population" .format(percent['Pop2022']))

"""## Summary Statistics and Axes

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/ax.png)
Suppose I have customers of my vinyl record shop rate different artists

|Customer | Taylor Swift | Miranda Lambert | Carrie Underwood | Nicki Minaj | Ariana Grande |
|:-----------|:------:|:------:|:---------:|:------:|:--------:|
|Jake|5|-|5|2|2|
|Clara|2|-|-|4|5|
|Kelsey|5|5|5|2|-|
|Angelica|2|3|-|5|5|
|Jordyn|2|1|-|5|-|

First we will read in the file ...
"""

ratings = pd.read_csv('https://raw.githubusercontent.com/zacharski/ml-class/master/data/ratings.csv', index_col=0)
ratings

"""We can get the mean rating of each artist by:

"""

ratings.mean()

"""Note that the summary statistics ignore NaN entries. The mean rating for Miranda Lambert is computed just on the people that rated her.

Many descriptive statistics functions take an optional parameter `axis` that tells which axis to reduce over. If we want the mean ratings for each **customer** instead of each artist we can do:
"""

ratings.mean(axis=1)

"""

Sweet! So `axis=1` means reduce by rows and `axis=0` means reduce by columns:"""

ratings.mean(axis=0)

"""![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

## List of Descriptive Statistics
(from the book *Python for Data Analysis*)

Method | Description
:-- | :--
`count` | Number of non-NaN values
`describe` | A set of common summary statistics
`min, max` | compute minimum and maximum values
`argmin, argmax` | compute index locations of minimum and maximum values
`sum` | Sum the values
`mean` | Mean of values
`median` | Median of values
`std` | Sample standard deviation

So, for example, the lowest rating for each artist:

"""

ratings.min()

"""
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/divider.png)

# <font color='#EE4C2C'>You Try ...</font> 
Ok, it is time for you to try out what you just learned. Let us start with the electric vehicle datafile we have already seen:

```
https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ElectricCarData_Clean.csv
```
When we loaded the datafile before, it worked fine for those examples, but you may encounter an error here, that will require you to modify the `read_csv`.

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/evBanner.png)"""

! curl https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ElectricCarData_Clean.csv

cars = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/ElectricCarData_Clean.csv',
                     na_values='-')
cars

"""Some of the columns are based on kilometers:

* TopSpeed_KmH	
* Range_Km	
* Efficiency_WhKm	
* FastCharge_KmH

and we are first going to add USA mile-centric columns.

## <font color='#EE4C2C'>1. TopSpeed_MPH</font>

Add a new column `TopSpeed_MPH` computed from the `TopSpeed_KmH` column, and just to check, display the first 10 rows. (The Lucid Air should have a top speed slightly over 155 MPH)

"""

cars['TopSpeed_MPH'] = cars['TopSpeed_KmH'] * 0.6214
#cars[:5][['Model', 'TopSpeed_MPH']]
cars

"""
## <font color='#EE4C2C'>2. Range and FastCharge_MPH</font>

Add a new column `Range` computed from the `Range_Km` column that shows the range in miles.

Also add a column `FastCharge_MPH computed from `FastCharge_KmH`. This will indicate how many miles can you go on one hour of charging. 

Just to check, display the first 10 rows. (The Tesla Model 3 Long Range Dual Motor should have a range of nearly 280 miles and charge at a rate of 584 miles per hour of fast charging.)"""

cars['Range'] = cars['Range_Km'] * 0.6214

cars['FastCharge_MPH'] = (cars['FastCharge_KmH'] * 0.6214)

cars[:10]

"""## <font color='#EE4C2C'>3. Efficiency_MkwH</font>

The DataFrame has a column `Efficiency_WhKm` which indicates how many watt hours does it take to go one kilometer. One common measure of efficieny is how many miles can you go on one kilowatt hour (kwH). So please add this column to the DataFrame. (The Tesla Model 3 Standard Range Plus should have an efficiency of around 4 miles per kilowatt hour.) 

"""

cars['Efficiency_MkwH'] = (cars['Efficiency_WhKm'] / 38.25)
cars

"""## <font color='#EE4C2C'>4. New DataFrame</font>

Create a new DataFrame, `bevs` (battery electric vehicles as opposed to PHEVs) that contain only the following columns from the current DataFrame

* Brand	
* Model	
* PowerTrain	
* AccelSec
* TopSpeed_MPH	
* Range	
* Efficiency_MkwH

```
'Brand', 'Model', 'PowerTrain', 'AccelSec', 'TopSpeed_MPH', 'Range', 'Efficiency_MkwH'
```

"""

bevs = DataFrame(cars)
bevs[['Brand', 'Model', 'PowerTrain', 'AccelSec', 'TopSpeed_MPH', 'Range', 'Efficiency_MkwH']]

"""## <font color='#EE4C2C'>5. Most and least efficient</font>
Using the bevs DataFrame, what are the 5 most efficient evs ordered by the most efficient first?

"""

bevs.sort_values(by=['Efficiency_MkwH'], ascending=False)[:5]

"""What are the five most inefficient evs ordered by least efficient first?"""

bevs.sort_values(by=['Efficiency_MkwH'], ascending=True)[:5]

"""## <font color='#EE4C2C'>6. fastest
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/porsche.png)

The Porsche 911 997 Turbo S is among the world's fastest production combustion cars with a 0-60 acceleration of 2.9 seconds. (In our dataset `AccelSec` measures the same thing.) Which electric cars have better acceleration than this? 
"""

bevs2 = bevs.loc[bevs['AccelSec'] < 3.0]
bevs2

"""## <font color='#EE4C2C'>7. Refrigerators
![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/frigTesla.png)

Representative Thomas Massie (R-KY) at a hearing questioning Secretarty Pete Buttigieg says the energy (kWh) required to home charge an electric vehicle for a year is 25 times greater than running the average refrigerator. He also said "It would take four times as much electricity to charge the average household's cars as the average household uses on air conditioning." And he said, "that means the average household would use twice as much electricity charging one of their cars as they would use for all of the air conditioning that they use for the entire year." Is this true? 

Since air conditioner use is quite varied in different regions of the country, perhaps a better measure would be the energy used for air conditioning and heating combined.

You are going to need to do some web searching to find the typical energy use of household these household items.

What do you think about the usefulness of this comparing household appliances to EVs when making government policy?

Government policies are required to be made in favor of the people. Since most people are not able to fully understand the scientific measures and units when it come for measuring the power consumption like kWh and most of them would not get what is that unit. For a better understanding of the common people the government should promote the comparisons based on their daily life uses like the use of refrigerators and use of air conditioners .

Precisely these units of measurements are not accurate and cannot be fully used as a formal unit of measurements as these are only comparable values and are not fixed. The average household consumption of electricity is not a definite value but people can easily grasp what it means charging of an EV as compared to use of AC or fridge. Their uses are different across different regions and in the year. For a colder region the use of fridge and AC is minimal but for a hotter region the use is grater , thus more consumption of power in that region. So, government should aim to make the common comparison units taking into account the region and other factors.

## <font color='#EE4C2C'>8. Global Adoption of EVs

![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/earth.png)

The data file we are using for this is

```
https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/IEA-EV-data.csv
```

This data is from the [International Energy Agency](https://www.iea.org/data-and-statistics/data-product/global-ev-outlook-2022).

The first step in data mining work is to examine the dataset, which often is not in the best format to directly answer our questions. That is the case with this file. You have the Pandas skills, but you will need to spend a bit of time looking at the datafile and understanding it, so you can write some code to meet the need.

So what is our need? We are interested in what percent of new car sales are evs in 2021. We are interested in historical data, not predictions. We would like to see the top five countries with the best adoption percent and the bottom five. Have appropriate labels indicating the list of top 5 and bottom 5.
"""

from pandas import Series, DataFrame
import pandas as pd
data = pd.read_csv('https://raw.githubusercontent.com/zacharski/datamining-guide/main/data/IEA-EV-data.csv',
                     na_values='-')

cars1=DataFrame(data)
#cars1=DataFrame(data,index=['powertrain'])
cars1

cars1['powertrain']
cars1[['powertrain','year']]
( (cars1['powertrain']=='EV') & (cars1['year']== 2021) ).sum()

total = 915/7016
total

"""## <font color='#EE4C2C'>9. Adoption of EVs Worldwide Part 2
In the U.S. in 2021 Electric Vehicles account for 2.5% of total new car sales. Is this higher or lower than the average (mean) 2021 figures in our dataset?

Also, how many countries have a higher adoption rate than the U.S?

In addition to cells showing your work, please have some readable content.
"""

value1 = 7016*0.025
value1
(cars1['year']== 2021).mean()
#915>175.4

"""The electric vehicles accountting for 2.5% of total new cars sales are 175.4 total, this percentage is not higher than the avg mean of 2021 0.025<0.13"""

cars1[['region','value']]
cars1[cars1['region']== 'USA'].mean()
cars1[cars1['value'] > 3054615.549 ]